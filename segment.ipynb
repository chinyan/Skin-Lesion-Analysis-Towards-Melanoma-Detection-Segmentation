{
  "cells": [
    {
      "metadata": {
        "_uuid": "f16ff18e15a70c12ffef0611acefb7ee54643769"
      },
      "cell_type": "markdown",
      "source": "# Setting up working directory[](http://)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "229a7a51f77b20cd6dd503ce1b00da507d6b293e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "!cp -rf ../input/isbi2017-part1-master/* /kaggle/working/",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f40e5f0fd5c284a38bb549cc94029d4318690c24",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "!ls",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "58f70998cea7f0619788520270782fe3fbe78535"
      },
      "cell_type": "markdown",
      "source": "# Main code"
    },
    {
      "metadata": {
        "_uuid": "9024bdaa28a4bba8de4a67401f1a8a2032250453"
      },
      "cell_type": "markdown",
      "source": "## Import libraries"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import os\nimport numpy as np\nimport pandas as pd\nfrom keras.optimizers import Adam, SGD\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport pickle as pkl\nimport ISIC_dataset as ISIC\nfrom metrics import dice_loss, jacc_loss, jacc_coef, dice_jacc_mean",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fbcaf181dae990055c8abc9f5a84ebfe539d31c8"
      },
      "cell_type": "markdown",
      "source": "## Set image dimension ordering to Theano dimension ordering"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "57c633f6b44249412a9e42bbbfd6e6626d0e2e94"
      },
      "cell_type": "code",
      "source": "np.random.seed(4)\nK.set_image_dim_ordering('th')  # Theano dimension ordering: (channels, width, height)\n                                # some changes will be necessary to run with tensorflow",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "07facd13dba755639c2cb19398e4463f84fbc8dd"
      },
      "cell_type": "markdown",
      "source": "## Folder initialization"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "1c03c2889be743987286a85bac6d08b77cc185d1"
      },
      "cell_type": "code",
      "source": "# Lesion Segmentation: Training Image and Mask\ntraining_folder = \"datasets/ISIC-2017_Training_Data\"\ntraining_mask_folder = \"datasets/ISIC-2017_Training_Part1_GroundTruth\"\n\n# Lesion Classification: Training Labels\ntraining_labels_csv = \"datasets/ISIC-2017_Training_Part3_GroundTruth.csv\"\n\n# Lesion Segmentation: Validation Image\nvalidation_folder = \"datasets/ISIC-2017_Validation_Data\"\n# Lesion Segmentation: Test Image\ntest_folder = \"datasets/ISIC-2017_Test_v2_Data\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4a91f99a8d5390de5db38159788358aed8d6ba11"
      },
      "cell_type": "markdown",
      "source": "## Main code settings"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "8b617a7e777cf54ab881f1a81d5af9fcda453457"
      },
      "cell_type": "code",
      "source": "# Resize image dimension\nheight, width = 128, 128\n\n# Image parameters\nmean_type = 'imagenet' # 'sample' 'samplewise'\nrescale_mask = True\nuse_hsv = False\ndataset = 'isic' # 'isic' 'isicfull' 'isic_noval_notest' 'isic_other_split' 'isic_notest'\n\n# Model parameters\nmodel_name = \"model1\"\nseed = 1\nnb_epoch = 1  # 220\ninitial_epoch = 0 \nbatch_size = 4\nloss_param = 'dice'\noptimizer_param = 'adam'\nmonitor_metric = 'val_jacc_coef'\nfc_size = 8192\n\n# Run-time flags\ndo_train = True # train network and save as model_name\ndo_predict = True # use model to predict and save generated masks for Validation/Test\ndo_ensemble = False # use previously saved predicted masks from multiple models to generate final masks\nensemble_pkl_filenames = [\"model1\",\"model2\", \"model3\", \"model4\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f6aa7f52c0e420ff47e9e7944ee4be76d617f516",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Training metric options\nmetrics = [jacc_coef]\n\n# HSV options: On or off\nif use_hsv:\n    n_channels = 6\n    print(\"Using HSV\")\nelse:\n    n_channels = 3\n\n\n# Image mean options\nprint((\"Using {} mean\".format(mean_type)))\n\nremove_mean_imagenet   = False\nremove_mean_samplewise = False\nremove_mean_dataset    = False\n\nif mean_type == 'imagenet':\n    remove_mean_imagenet = True\n    \nelif mean_type == 'sample':\n    remove_mean_samplewise = True\n    \nelif mean_type == 'dataset':\n    remove_mean_dataset = True\n    train_mean = np.array([[[ 180.71656799]],[[ 151.13494873]],[[ 139.89967346]]]);\n    train_std = np.array([[[1]],[[1]],[[ 1]]]); # not using std\n\nelse:\n    raise Exception(\"Wrong mean type\")\n    \n\n# Loss options    \nloss_options = {'BCE': 'binary_crossentropy', 'dice':dice_loss, 'jacc':jacc_loss, 'mse':'mean_squared_error'}\nloss = loss_options[loss_param]\n\n\n# Optimizer options\noptimizer_options = {'adam': Adam(lr=1e-5),\n                     'sgd': SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)}\noptimizer = optimizer_options[optimizer_param]\n\n\n# Specify model filename\nmodel_filename = \"weights/{}.h5\".format(model_name)\n\n\nprint('Create model')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a13cf1a3ed5a64f6b0b4a5d308ab5bb9f13245c2"
      },
      "cell_type": "markdown",
      "source": "## Specify network architecture for training"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "c74a1593047e37e3562bbd8676c9a26078a8fc05"
      },
      "cell_type": "code",
      "source": "import numpy as np\nfrom keras.models import Model\nfrom keras.layers import merge, Flatten, Dense, Input, Dropout, Activation, Reshape\nfrom keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, UpSampling2D, Conv2DTranspose\nfrom keras.layers import BatchNormalization\nfrom keras.layers.noise import GaussianNoise\n\nfrom keras.layers import concatenate\n\nimport h5py\nnp.random.seed(4)\n\n# VGG16_WEIGHTS_NOTOP = 'pretrained_weights/vgg16_notop.h5'\nVGG16_WEIGHTS_NOTOP = 'pretrained_weights/vgg16_weights.h5'\n# download .h5 weights from https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n\ndef Unet3(img_rows, img_cols, loss , optimizer, metrics, fc_size = 8192, channels = 3):\n    filter_size = 5\n    filter_size_2 = 11\n    dropout_a = 0.5\n    dropout_b = 0.5\n    dropout_c = 0.5\n    gaussian_noise_std = 0.025\n\n    inputs = Input((channels, img_rows, img_cols))\n    input_with_noise = GaussianNoise(gaussian_noise_std)(inputs)\n\n    conv1 = Conv2D(32, (filter_size, filter_size), activation='relu', padding='same')(input_with_noise)\n    conv1 = Conv2D(32, (filter_size, filter_size), activation='relu', padding='same')(conv1)\n    conv1 = Conv2D(32, (filter_size, filter_size), activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D((2, 2), strides=(2, 2))(conv1)\n    pool1 = GaussianNoise(gaussian_noise_std)(pool1)\n\n    conv2 = Conv2D(64, (filter_size, filter_size), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(64, (filter_size, filter_size), activation='relu', padding='same')(conv2)\n    conv2 = Conv2D(64, (filter_size, filter_size), activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D((2, 2), strides=(2, 2))(conv2)\n    pool2 = GaussianNoise(gaussian_noise_std)(pool2)\n\n    conv3 = Conv2D(128, (filter_size, filter_size), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(128, (filter_size, filter_size), activation='relu', padding='same')(conv3)\n    conv3 = Conv2D(128, (filter_size, filter_size), activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D((2, 2), strides=(2, 2))(conv3)\n    pool3 = Dropout(dropout_a)(pool3)\n\n    convn = Conv2D(256, (filter_size, filter_size), activation='relu', padding='same')(pool3)\n    convn = Conv2D(256, (filter_size, filter_size), activation='relu', padding='same')(convn)\n    convn = Conv2D(256, (filter_size, filter_size), activation='relu', padding='same')(convn)\n    pooln = MaxPooling2D((2, 2), strides=(2, 2))(convn)\n    pooln = Dropout(dropout_a)(pooln)\n\n    fc = Flatten()(pooln)\n    fc = Dense(4096, activation='relu')(fc)\n    fc = Dropout(dropout_b)(fc)\n\n    n = img_rows / 2 / 2 / 2 / 2\n    fc = Dense(int(256 * n * n), activation='relu')(fc)\n    fc = GaussianNoise(gaussian_noise_std)(fc)\n    fc = Reshape((256, int(n), int(n)))(fc)\n\n    up0 = concatenate([UpSampling2D(size=(2, 2))(fc), convn], axis=1)\n    up0 = Dropout(dropout_c)(up0)\n\n    convp = Conv2D(256, (filter_size_2, filter_size_2), activation='relu', padding='same')(up0)\n    convp = Conv2D(256, (filter_size, filter_size), activation='relu', padding='same')(convp)\n    convp = Conv2D(128, (filter_size, filter_size), activation='relu', padding='same')(convp)\n\n    up1 = concatenate([UpSampling2D(size=(2, 2))(convp), conv3], axis=1)\n    up1 = Dropout(dropout_c)(up1)\n\n    conv4 = Conv2D(128, (filter_size_2, filter_size_2), activation='relu', padding='same')(up1)\n    conv4 = Conv2D(128, (filter_size, filter_size), activation='relu', padding='same')(conv4)\n    conv4 = Conv2D(64, (filter_size, filter_size), activation='relu', padding='same')(conv4)\n\n    up2 = concatenate([UpSampling2D(size=(2, 2))(conv4), conv2], axis=1)\n    up2 = Dropout(dropout_c)(up2)\n\n    conv5 = Conv2D(64, (filter_size_2, filter_size_2), activation='relu', padding='same')(up2)\n    conv5 = Conv2D(64, (filter_size, filter_size), activation='relu', padding='same')(conv5)\n    conv5 = Conv2D(32, (filter_size, filter_size), activation='relu', padding='same')(conv5)\n\n    up3 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv1], axis=1)\n    up3 = Dropout(dropout_c)(up3)\n\n    conv6 = Conv2D(32, (filter_size_2, filter_size_2), activation='relu', padding='same')(up3)\n    conv6 = Conv2D(32, (filter_size, filter_size), activation='relu', padding='same')(conv6)\n    conv6 = Conv2D(32, (filter_size, filter_size), activation='relu', padding='same')(conv6)\n\n    conv7 = Conv2D(1, (1, 1), activation='sigmoid')(conv6)\n\n    model = Model(inputs=inputs, outputs=conv7)\n    model.summary()\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model\n\ndef VGG16(img_rows, img_cols, pretrained, freeze_pretrained, loss , optimizer, metrics, channels=3):\n    inputs = Input((channels, img_rows, img_cols))\n    \n    pad1 = ZeroPadding2D((1, 1), input_shape=(channels, img_rows, img_cols))(inputs)\n    conv1 = Conv2D(64, (3, 3), activation='relu', name='conv1_1')(pad1)\n    conv1 = ZeroPadding2D((1, 1))(conv1)\n    conv1 = Conv2D(64, (3, 3), activation='relu', name='conv1_2')(conv1)\n    pool1 = MaxPooling2D((2, 2), strides=(2, 2))(conv1)\n\n    pad2 = ZeroPadding2D((1, 1))(pool1)\n    conv2 = Conv2D(128, (3, 3), activation='relu', name='conv2_1')(pad2)\n    conv2 = ZeroPadding2D((1, 1))(conv2)\n    conv2 = Conv2D(128, (3, 3), activation='relu', name='conv2_2')(conv2)\n    pool2 = MaxPooling2D((2, 2), strides=(2, 2))(conv2)\n\n    pad3 = ZeroPadding2D((1, 1))(pool2)\n    conv3 = Conv2D(256, (3, 3), activation='relu', name='conv3_1')(pad3)\n    conv3 = ZeroPadding2D((1, 1))(conv3)\n    conv3 = Conv2D(256, (3, 3), activation='relu', name='conv3_2')(conv3)\n    conv3 = ZeroPadding2D((1, 1))(conv3)\n    conv3 = Conv2D(256, (3, 3), activation='relu', name='conv3_3')(conv3)\n    pool3 = MaxPooling2D((2, 2), strides=(2, 2))(conv3)\n\n    pad4 = ZeroPadding2D((1, 1))(pool3)\n    conv4 = Conv2D(512, (3, 3), activation='relu', name='conv4_1')(pad4)\n    conv4 = ZeroPadding2D((1, 1))(conv4)\n    conv4 = Conv2D(512, (3, 3), activation='relu', name='conv4_2')(conv4)\n    conv4 = ZeroPadding2D((1, 1))(conv4)\n    conv4 = Conv2D(512, (3, 3), activation='relu', name='conv4_3')(conv4)\n    pool4 = MaxPooling2D((2, 2), strides=(2, 2))(conv4)\n\n    pad5 = ZeroPadding2D((1, 1))(pool4)\n    conv5 = Conv2D(512, (3, 3), activation='relu', name='conv5_1')(pad5)\n    conv5 = ZeroPadding2D((1, 1))(conv5)\n    conv5 = Conv2D(512, (3, 3), activation='relu', name='conv5_2')(conv5)\n    conv5 = ZeroPadding2D((1, 1))(conv5)\n    conv5 = Conv2D(512, (3, 3), activation='relu', name='conv5_3')(conv5)\n\n    # Additional seven-layers just for loading weights from VGG-16\n    pool_a = MaxPooling2D((2, 2), strides=(2, 2))(conv5)\n    flat_a = Flatten()(pool_a)\n    dense_a = Dense(4096, activation='relu')(flat_a)\n    dense_a = Dropout(0.5)(dense_a)\n    dense_b = Dense(4096, activation='relu')(dense_a)\n    dense_b = Dropout(0.5)(dense_b) \n    dense_c = Dense(1000, activation='softmax')(dense_b)\n    \n    model = Model(inputs=inputs, outputs=dense_c)\n    \n    # Load weights\n    if pretrained:\n        weights_path = VGG16_WEIGHTS_NOTOP\n        model.load_weights(weights_path, by_name=True)\n        \n        if freeze_pretrained:\n            for layer in model.layers:\n                layer.trainable = False\n    \n    # Remove the last seven-layers\n    for i in range(7):\n        model.layers.pop()\n    \n    dropout_val = 0.5\n    \n    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=1)\n    up6 = Dropout(dropout_val)(up6)\n\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=1)\n    up7 = Dropout(dropout_val)(up7)\n\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n\n    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=1)\n    up8 = Dropout(dropout_val)(up8)\n\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n\n    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=1)\n    up9 = Dropout(dropout_val)(up9)\n\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\n    model = Model(inputs=inputs, outputs=conv10)\n    model.summary()\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "19f36379afb9ab8b9d97fa93a3cde97651832fdb",
        "scrolled": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# import models\nmodel = 'vgg'\n\nif model == 'unet':\n    model = Unet(height, width,\n                 loss=loss,\n                 optimizer=optimizer,\n                 metrics=metrics,\n                 fc_size=fc_size,\n                 channels=n_channels)\n\nelif model == 'unet2':\n    model = Unet2(height, width,\n                  loss=loss,\n                  optimizer=optimizer,\n                  metrics=metrics,\n                  fc_size=fc_size,\n                  channels=n_channels)\n\nelif model == 'unet3':\n    model = Unet3(height, width,\n                  loss=loss,\n                  optimizer=optimizer,\n                  metrics=metrics,\n                  fc_size=fc_size,\n                  channels=n_channels)\n\nelif model == 'vgg':\n    model = VGG16(height, width,\n                  pretrained=True,\n                  freeze_pretrained=False,\n                  loss=loss,\n                  optimizer=optimizer,\n                  metrics=metrics)\nelse:\n    print(\"Incorrect model name\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "c7ad3a552bded60894ea3b49d6745fd84af7d109"
      },
      "cell_type": "code",
      "source": "def myGenerator(train_generator, train_mask_generator, remove_mean_imagenet=True, rescale_mask=True, use_hsv=False):\n    while True:\n        train_gen = next(train_generator)\n        train_mask = next(train_mask_generator)\n                \n        if False: # use True to show images\n            mask_true_show = np.where(train_mask>=0.5, 1, 0)\n            mask_true_show = mask_true_show * 255\n            mask_true_show = mask_true_show.astype(np.uint8)\n            for i in range(train_gen.shape[0]):\n                mask = train_mask[i].reshape((width,height))\n                img=train_gen[i]\n                img = img[0:3]\n                img = img.astype(np.uint8)\n                img = img.transpose(1,2,0)\n                f, ax = plt.subplots(1, 2)\n                ax[0].imshow(img); ax[0].axis(\"off\");\n                ax[1].imshow(mask, cmap='Greys_r'); ax[1].axis(\"off\"); plt.show()\n        yield (train_gen, train_mask)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "087d960b3ef724401ff3b5e2c586d3dba6e40008",
        "scrolled": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "if do_train:\n    if dataset == 'isicfull':\n        n_samples = 2000 # per epoch\n        print(\"Using ISIC full dataset\")\n        \n        # Get train, validation and test image list\n        train_list, val_list, test_list = ISIC.train_val_test_from_txt(isicfull_train_split, \n                                                                       isicfull_val_split, \n                                                                       isicfull_test_split)\n        \n        # Folder for resized images\n        base_folder = \"datasets/isicfull_{}_{}\".format(height,width)\n        image_folder = os.path.join(base_folder,\"image\")\n        mask_folder = os.path.join(base_folder,\"mask\")\n        \n        # Create folder and generate resized images if folder does not exists\n        if not os.path.exists(base_folder):  \n            print(\"Begin resizing...\")\n            \n            ISIC.resize_images(train_list+val_list+test_list, \n                               input_image_folder = isicfull_folder,\n                               input_mask_folder = isicfull_mask_folder, \n                               output_image_folder = image_folder.format(height,width), \n                               output_mask_folder = mask_folder, \n                               height = height, \n                               width = width)\n            \n            print(\"Done resizing...\")\n            \n    else:\n        print(\"Using ISIC 2017 dataset\")\n        \n        # Folders for resized images\n        base_folder = \"datasets/isic_{}_{}\".format(height, width)\n        image_folder = os.path.join(base_folder, \"image\")\n        mask_folder = os.path.join(base_folder, \"mask\")\n\n        # train_list, train_label, test_list, test_label = ISIC.train_test_from_yaml(yaml_file = training_split_yml, csv_file = training_labels_csv)\n        \n        # Get train, validation and test image list based on training dataset\n        df = pd.read_csv(training_labels_csv)\n        df['image_id'] = df['image_id'].astype(str) + '.jpg'\n        train_list, test_list, train_label, test_label = ISIC.train_val_split(df['image_id'].tolist(), df['melanoma'].tolist(), seed = seed, val_split = 0.20)\n        train_list, val_list, train_label, val_label = ISIC.train_val_split(train_list, train_label, seed = seed, val_split = 0.20)\n        \n        # Create folder and generate resized images if folder does not exists\n        if not os.path.exists(base_folder):\n            ISIC.resize_images(train_list+val_list+test_list,\n                               input_image_folder = training_folder, \n                               input_mask_folder = training_mask_folder, \n                               output_image_folder = image_folder, \n                               output_mask_folder = mask_folder, \n                               height = height, \n                               width = width)\n            \n        if dataset == \"isic_notest\": # previous validation split will be used for training\n            train_list = train_list + val_list\n            val_list = test_list\n            \n        elif dataset ==\"isic_noval_notest\": # previous validation/test splits will be used for training\n            monitor_metric = 'jacc_coef'\n            train_list = train_list + val_list + test_list \n            val_list = test_list\n            \n        elif dataset ==\"isic_other_split\": # different split, uses previous val/test for training\n            seed = 82\n            train_list1, train_list2, train_label1, train_label2 = ISIC.train_val_split(train_list, train_label, seed=seed, val_split=0.30)\n            train_list = val_list+test_list+train_list1 \n            val_list = train_list2\n            test_list = val_list \n            \n        n_samples = len(train_list)\n        # n_samples = 20\n        \n    print(\"Loading images\")\n    # Assign train, validation and test image and mask based on training dataset \n    train, train_mask = ISIC.load_images(train_list, \n                                         height, width, \n                                         image_folder, mask_folder,\n                                         remove_mean_imagenet = remove_mean_imagenet,\n                                         rescale_mask = rescale_mask, \n                                         use_hsv = use_hsv, \n                                         remove_mean_samplewise = remove_mean_samplewise)\n    \n    val, val_mask = ISIC.load_images(val_list, height, width, \n                                     image_folder, mask_folder,  \n                                     remove_mean_imagenet = remove_mean_imagenet, \n                                     rescale_mask = rescale_mask, \n                                     use_hsv = use_hsv, \n                                     remove_mean_samplewise = remove_mean_samplewise)\n    \n    test, test_mask = ISIC.load_images(test_list, height, width, \n                                       image_folder, mask_folder,\n                                       remove_mean_imagenet = remove_mean_imagenet, \n                                       rescale_mask = rescale_mask, \n                                       use_hsv = use_hsv, \n                                       remove_mean_samplewise = remove_mean_samplewise)\n    print(\"Done loading images\")\n    \n    # Remove mean of train, val and test images\n    if remove_mean_dataset:  # Only True when specify mean_type = 'dataset'\n        print((\"\\nUsing Train Mean: {} Std: {}\".format(train_mean, train_std)))\n        train = (train - train_mean)/train_std\n        val   = (val - train_mean)/train_std\n        test  = (test - train_mean)/train_std\n\n    # Batch size \n    print((\"Using batch size = {}\".format(batch_size)))\n    \n    print('Fit model')\n    # Save best model\n    model_checkpoint = ModelCheckpoint(model_filename, monitor=monitor_metric, save_best_only=True, verbose=1)\n    \n    # Define dictionary for data augmentation\n    data_gen_args = dict(featurewise_center = False, \n                         samplewise_center = remove_mean_samplewise,\n                         featurewise_std_normalization = False, \n                         samplewise_std_normalization = False, \n                         zca_whitening = False, \n                         rotation_range = 270, \n                         width_shift_range = 0.1, \n                         height_shift_range = 0.1, \n                         horizontal_flip = False, \n                         vertical_flip = False, \n                         zoom_range = 0.2,\n                         channel_shift_range = 0,\n                         fill_mode = 'reflect',\n                         dim_ordering = K.image_dim_ordering())\n    data_gen_mask_args = dict(list(data_gen_args.items()) + list({'fill_mode':'nearest','samplewise_center':False}.items()))\n    \n    # Perform data augmentation using Keras ImageDataGenerator\n    print(\"Create Data Generator\")\n    train_datagen = ImageDataGenerator(data_gen_args)\n    train_mask_datagen = ImageDataGenerator(data_gen_mask_args)\n    train_generator = train_datagen.flow(train, batch_size=batch_size, seed=seed)\n    train_mask_generator = train_mask_datagen.flow(train_mask, batch_size=batch_size, seed=seed)\n    train_generator_f = myGenerator(train_generator, train_mask_generator, remove_mean_imagenet=remove_mean_imagenet, rescale_mask=rescale_mask, use_hsv=use_hsv)\n    \n    # Train model using train list and validate using val list\n    if dataset == \"isic_noval_notest\":\n        print(\"Not using validation during training\")\n        history = model.fit_generator(train_generator_f,\n                                      # samples_per_epoch=n_samples,\n                                      steps_per_epoch = n_samples,\n                                      nb_epoch = nb_epoch,\n                                      callbacks = [model_checkpoint], \n                                      initial_epoch = initial_epoch)\n    else:  # default model fitting\n        model.load_weights(model_filename)\n        history = model.fit_generator(train_generator_f,\n                                      # samples_per_epoch=n_samples,\n                                      steps_per_epoch = n_samples,\n                                      nb_epoch=nb_epoch, \n                                      validation_data=(val,val_mask), \n                                      callbacks=[model_checkpoint], \n                                      initial_epoch=initial_epoch)\n\n    train = None\n    train_mask = None # clear memory\n    \n    # Load best saved checkpoint after training\n    print(\"Load best checkpoint\")\n    model.load_weights(model_filename) \n\n    # Evaluate model using val list and test list aka subset of training dataset\n    mask_pred_val = model.predict(val) \n    mask_pred_test = model.predict(test)\n    \n    for pixel_threshold in [0.5]: #np.arange(0.3,1,0.05):\n        # Predict mask for val list\n        mask_pred_val = np.where(mask_pred_val>=pixel_threshold, 1, 0)  # assign pixel 0/1 based on output layer activation value\n        mask_pred_val = mask_pred_val * 255  # assign 0 -> 0 and 1 -> 255\n        mask_pred_val = mask_pred_val.astype(np.uint8)\n        print(\"Validation Predictions Max: {}, Min: {}\".format(np.max(mask_pred_val), np.min(mask_pred_val)))\n        \n        # Evaluate Jaccard score for val\n        print(model.evaluate(val, val_mask, batch_size = batch_size, verbose=1))\n        dice, jacc = dice_jacc_mean(val_mask, mask_pred_val, smooth = 0)\n        print(model_filename)\n        print(\"Resized val dice coef      : {:.4f}\".format(dice))\n        print(\"Resized val jacc coef      : {:.4f}\".format(jacc))\n\n        # Predict mask for test list\n        mask_pred_test = np.where(mask_pred_test>=pixel_threshold, 1, 0)\n        mask_pred_test = mask_pred_test * 255\n        mask_pred_test = mask_pred_test.astype(np.uint8)\n        \n        # Evaluate Jaccard score for test\n        print(model.evaluate(test, test_mask, batch_size = batch_size, verbose=1))\n        dice, jacc = dice_jacc_mean(test_mask, mask_pred_test, smooth = 0)\n        print(\"Resized test dice coef      : {:.4f}\".format(dice))\n        print(\"Resized test jacc coef      : {:.4f}\".format(jacc))\nelse:\n    # Load model directly when do_train=False\n    print('Load model')\n    model.load_weights(model_filename)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "60de2c20353d465566fbca3993594e2be8ecc7f5"
      },
      "cell_type": "code",
      "source": "def predict_challenge(challenge_folder, challenge_predicted_folder, mask_pred_challenge=None, plot=True):\n    # Get challenge folder and create new folder with resized images\n    challenge_list = ISIC.list_from_folder(challenge_folder)\n    challenge_resized_folder = challenge_folder+\"_{}_{}\".format(height,width)\n    \n    if not os.path.exists(challenge_resized_folder):\n        ISIC.resize_images(challenge_list, \n                           input_image_folder=challenge_folder, \n                           input_mask_folder=None, \n                           output_image_folder=challenge_resized_folder, \n                           output_mask_folder=None, \n                           height=height, \n                           width=width)\n\n    challenge_resized_list =  [name.split(\".\")[0]+\".png\" for name in challenge_list]\n    challenge_images = ISIC.load_images(challenge_resized_list, \n                                        height, width, image_folder=challenge_resized_folder,\n                                        mask_folder=None, \n                                        remove_mean_imagenet=True, \n                                        use_hsv = use_hsv,\n                                        remove_mean_samplewise=remove_mean_samplewise)\n    \n    # Remove image mean from dataset\n    if remove_mean_dataset:\n        challenge_images = (challenge_images-train_mean)/train_std\n    if mask_pred_challenge is None:\n        mask_pred_challenge = model.predict(challenge_images)\n        \n    with open('{}.pkl'.format(os.path.join(challenge_predicted_folder,model_name)), 'wb') as f:\n        pkl.dump(mask_pred_challenge, f)\n        \n    # Create mask prediction for challenge images\n    mask_pred_challenge = np.where(mask_pred_challenge>=0.5, 1, 0)\n    mask_pred_challenge = mask_pred_challenge * 255\n    mask_pred_challenge = mask_pred_challenge.astype(np.uint8)\n\n    challenge_predicted_folder = os.path.join(challenge_predicted_folder, model_name)\n    if not os.path.exists(challenge_predicted_folder):\n        os.makedirs(challenge_predicted_folder)\n\n    print(\"Start challenge prediction:\")\n    for i in range(len(challenge_list)):\n        print((\"{}: {}\".format(i, challenge_list[i])))\n        # Revert predicted mask to original image resolution\n        ISIC.show_images_full_sized(image_list = challenge_list, \n                                    img_mask_pred_array = mask_pred_challenge, \n                                    image_folder=challenge_folder, \n                                    mask_folder=None, \n                                    index = i, \n                                    output_folder=challenge_predicted_folder, \n                                    plot=plot)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "e0dad11ea9bfc5193dd3fd827a4b4ac9876de1a7"
      },
      "cell_type": "code",
      "source": "def join_predictions(pkl_folder, pkl_files, binary=False, threshold=0.5):\n    n_pkl = float(len(pkl_files))\n    array = None\n    for fname in pkl_files:\n        with open(os.path.join(pkl_folder,fname+\".pkl\"), \"rb\") as f:\n            tmp = pkl.load(f)\n            if binary:\n                tmp = np.where(tmp>=threshold, 1, 0)\n            if array is None:\n                array = tmp\n            else:\n                array = array + tmp\n    return array/n_pkl",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "718a238cc266279360691e52b896a2692cb25c45"
      },
      "cell_type": "code",
      "source": "validation_folder = 'datasets/ISIC-2017_Validation_Data'\nvalidation_predicted_folder = 'results/ISIC-2017_Validation_Predicted'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a172e5a8802fdc58fe6bbf1b88c8a1ec94fb5ede"
      },
      "cell_type": "markdown",
      "source": "## Generate predicted mask"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "24bff9a9e7e72b72d5e533bec4488bfef3201592",
        "scrolled": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "if do_predict:\n    # free memory\n    train = None\n    train_mask = None\n    val = None\n    test = None \n    \n    print(\"Start Challenge Validation\")\n    predict_challenge(challenge_folder=validation_folder, challenge_predicted_folder=validation_predicted_folder, plot=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6255e00309864a343e933ee75bdd1d4ff7d29436"
      },
      "cell_type": "markdown",
      "source": "## Calculate Jaccard score"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a514c590e49af412046ce71103bc1eb0d52c3635",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nfrom keras import backend as K\nfrom sklearn.metrics import jaccard_similarity_score\n\n\n# Lesion Classification: Training Labels\ntraining_labels_csv = \"datasets/ISIC-2017_Training_Part3_GroundTruth.csv\"\nvalidation_labels_csv = \"datasets/ISIC-2017_Validation_Part3_GroundTruth.csv\"\ntest_labels_csv = \"datasets/ISIC-2017_Test_v2_Part3_GroundTruth.csv\"\n\n# Lesion Segmentation: Training Image and Mask\ntraining_folder = \"datasets/ISIC-2017_Training_Data\"\ntraining_mask_folder = \"datasets/ISIC-2017_Training_Part1_GroundTruth\"\n# Lesion Segmentation: Validation Image\nvalidation_folder = \"datasets/ISIC-2017_Validation_Data\"\nvalidation_mask_folder = \"datasets/ISIC-2017_Validation_Part1_GroundTruth/\"\nvalidation_pred_folder = \"results/ISIC-2017_Validation_Predicted/model1/\"\n# Lesion Segmentation: Test Image\ntest_folder = \"datasets/ISIC-2017_Test_v2_Data\"\ntest_mask_folder = \"datasets/ISIC-2017_Test_v2_Part1_GroundTruth/\"\ntest_pred_folder = \"results/ISIC-2017_Test_v2_Predicted/model1/\"\n\n\nsmooth_default = 1.\n\ndef dice_coef(y_true, y_pred, smooth = smooth_default, per_batch = True):\n    if not per_batch:\n        y_true_f = K.flatten(y_true)\n        y_pred_f = K.flatten(y_pred)\n        intersection = K.sum(y_true_f * y_pred_f)\n        return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    else: \n        y_true_f = K.batch_flatten(y_true)\n        y_pred_f = K.batch_flatten(y_pred)\n        intersec = 2. * K.sum(y_true_f * y_pred_f, axis=1, keepdims=True) + smooth\n        union = K.sum(y_true_f, axis=1, keepdims=True) + K.sum(y_pred_f, axis=1, keepdims=True) + smooth\n        return K.mean(intersec / union)\n    \ndef jacc_coef(y_true, y_pred, smooth = smooth_default):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth)\n    \ndef jacc_loss(y_true, y_pred):\n    return -jacc_coef(y_true, y_pred)\n\ndef dice_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n    \ndef dice_jacc_single(mask_true, mask_pred, smooth = smooth_default):\n    bool_true = mask_true.reshape(-1).astype(np.bool)\n    bool_pred = mask_pred.reshape(-1).astype(np.bool)\n    if bool_true.shape != bool_pred.shape:\n        raise ValueError(\"Masks of different sizes.\")\n\n    bool_sum = bool_true.sum() + bool_pred.sum()\n    if bool_sum == 0:\n        print(\"Empty mask\")\n        return 0,0\n    intersec = np.logical_and(bool_true, bool_pred).sum()\n    dice = 2. * intersec / bool_sum\n    jacc = jaccard_similarity_score(bool_true.reshape((1, -1)), bool_pred.reshape((1, -1)), normalize=True, sample_weight=None)\n    return dice, jacc\n\ndef dice_jacc_mean(mask_true, mask_pred, smooth = smooth_default):\n    dice = 0\n    jacc = 0\n    for i in range(mask_true.shape[0]):\n        current_dice, current_jacc = dice_jacc_single(mask_true=mask_true[i],mask_pred=mask_pred[i], smooth= smooth)\n        dice = dice + current_dice\n        jacc = jacc + current_jacc\n    return dice/mask_true.shape[0], jacc/mask_true.shape[0]\n\ndef list_from_folder(image_folder):\n    image_list = []\n    for image_filename in os.listdir(image_folder):\n        if image_filename.endswith(\".png\"):\n            image_list.append(image_filename)\n    print((\"Found {} images.\".format(len(image_list))))\n    return image_list\n\n\nprint(\"Calculating Jaccard Similarity Score for Validation Set\")\nval_mask_list = list_from_folder(validation_mask_folder)\ndf_val = pd.read_csv(validation_labels_csv)\njacc_val_list = []\ndice_val_list = []\nfor i in range(len(val_mask_list)):\n    print(str(i)+': '+str(val_mask_list[i]))\n    mask_true = cv2.imread(validation_mask_folder+str(val_mask_list[i]))\n    mask_pred = cv2.imread(validation_pred_folder+str(val_mask_list[i]))\n    dice, jacc = dice_jacc_single(mask_true=mask_true, mask_pred=mask_pred)\n    jacc_val_list.append(jacc)\n    dice_val_list.append(dice)\ndf_val['jacc'] = jacc_val_list\ndf_val['dice'] = dice_val_list\nprint(df_val.head())\nprint('Average Jaccard Score = '+str(np.mean(jacc_val_list)))\nprint('Average Dice coefficient = '+str(np.mean(dice_val_list)))\ndf_val.to_csv('val.csv', encoding='utf-8', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "b6840d9f4797f98cc2c9f709551cb84b3d647c37"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}